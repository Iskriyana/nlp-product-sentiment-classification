{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras import utils\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "home = os.getenv(\"HOME\")\n",
    "nlp_repo = os.path.join(home, 'git/nlp-product-sentiment-classification')\n",
    "\n",
    "# data\n",
    "train_csv_path = os.path.join(nlp_repo, 'data/03_processed/Train.csv')\n",
    "train_descr = pd.read_csv(train_csv_path)\n",
    "\n",
    "test_csv_path = os.path.join(nlp_repo, 'data/03_processed/Test.csv')\n",
    "test_descr = pd.read_csv(test_csv_path)\n",
    "\n",
    "# encoded tokens\n",
    "preprocessed_corpus_path_TF = os.path.join(\n",
    "    nlp_repo, 'data/03_processed/product_descr_preprocessed_TF.p')\n",
    "\n",
    "preprocessed_corpus_path_TF_oh = os.path.join(\n",
    "    nlp_repo, 'data/03_processed/product_descr_preprocessed_TF_oh.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Tokens\n",
    "\n",
    "# max_words = vocabulary size = our samples - number of most frequent words.\n",
    "# I set it to 10.000, although in this case there are less.\n",
    "# I do this to parametise the code.\n",
    "# Aleternatively, I can set it to the length of our vocabulary = word_index\n",
    "max_words = 10000\n",
    "\n",
    "# embedding_size = embedding dimensionality\n",
    "embedding_size = 10\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "model_path = \"product_descr_TF.h5\"\n",
    "epochs = 15\n",
    "batch_size = 28\n",
    "\n",
    "# For GloVe word-embeddings matrix (pre-trained model)\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameter Dictionary\n",
    "\n",
    "This dictionary contains all the parameters necessary for the model training. It is going to be saved with the trained model in order to log it. \n",
    "\n",
    "\n",
    "Inputs before running a new experiment: \n",
    "1. Define experiment name\n",
    "2. Define model architecture and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log results tologs/experiments/all_models_2020_12_02-10:44\n"
     ]
    }
   ],
   "source": [
    "logging = True\n",
    "\n",
    "saving = True\n",
    "\n",
    "PARAMS = {\n",
    "\n",
    "    # Define experiment name:\n",
    "    'experiment_name': 'all_models',\n",
    "\n",
    "    # List of models\n",
    "    'models': ['baseline', 'bow', 'fc_emb', 'fc_transf', 'lstm', 'lstm_transf' 'conv1d', 'conv1d_transf'],\n",
    "\n",
    "    # Parameters general:\n",
    "    'n_splits': 4,\n",
    "    'seed': 42,\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': 15,\n",
    "    'hidden_units': [16, 32, 64],\n",
    "    'embedding_size': [10, 20, 30, 100],\n",
    "\n",
    "    # Parameters for pre-trained word embeddings:\n",
    "    'embedding_dim': 100,\n",
    "\n",
    "    # Parameters for the Conv1D:\n",
    "    'conv_window': [3, 5, 7],\n",
    "}\n",
    "\n",
    "logdir = f'logs/experiments/{PARAMS[\"experiment_name\"]}_' + \\\n",
    "    datetime.datetime.now().strftime(\"%Y_%m_%d-%H:%M\")\n",
    "logdir_tb = f'logs/tensorboard/experiments/{PARAMS[\"experiment_name\"]}_' + \\\n",
    "    datetime.datetime.now().strftime(\"%Y_%m_%d-%H:%M\")\n",
    "\n",
    "# create logging folder and tensorboard callback function\n",
    "if logging:\n",
    "    print(f'Log results to{logdir}')\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    tensorboard_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir_tb)]\n",
    "\n",
    "else:\n",
    "    logdir = ''\n",
    "    lgdir_tb = ''\n",
    "    tensorboard_callbacks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tokens and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_corpus, one_hot=False):\n",
    "    if not one_hot:\n",
    "        sequences, word_index = pd.read_pickle(path_to_corpus)\n",
    "        \n",
    "        # max_len = sequence length - the text is cut off after this number of words\n",
    "        # in this case it is defined as the maximum sequence length in our list of tokenised sequences\n",
    "        max_len = np.max([len(x) for x in sequences])\n",
    "        data = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            sequences, maxlen=max_len)\n",
    "    else:\n",
    "        sequences, word_index = pd.read_pickle(path_to_corpus)\n",
    "        data = sequences\n",
    "\n",
    "    labels = train_descr.loc[:, 'Sentiment'].to_list()\n",
    "\n",
    "    return sequences, word_index, data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for bag-of-words with one-hot encoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6364, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_oh, word_index_oh, data_oh, labels_oh = load_data(\n",
    "    preprocessed_corpus_path_TF_oh, one_hot=True)\n",
    "sequences_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the models with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sequences after padding is (6364, 25)\n"
     ]
    }
   ],
   "source": [
    "sequences, word_index, data, labels = load_data(preprocessed_corpus_path_TF)\n",
    "print(f'Shape of sequences after padding is {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for the Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = './glove.6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((max_words+1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample the Minority Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_smote(data, labels):\n",
    "    oversample = SMOTE()\n",
    "    data, labels = oversample.fit_resample(data, labels)\n",
    "\n",
    "    counter = Counter(labels)\n",
    "    for k, v in counter.items():\n",
    "        per = v / len(labels) * 100\n",
    "        print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    # plot the distribution\n",
    "    plt.bar(counter.keys(), counter.values())\n",
    "    plt.show()\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for bag-of-words with one-hot encoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=2, n=3765 (25.000%)\n",
      "Class=1, n=3765 (25.000%)\n",
      "Class=3, n=3765 (25.000%)\n",
      "Class=0, n=3765 (25.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATR0lEQVR4nO3df6zd9X3f8eerxkC0RMWUO+bZVk0zbxGJGsPujNtUEwsLGE+qqZpFMCm4EZUbDaREqqaRTipNMrR0WsPEljK5xY2ZshCWpMVjzphDmKL8wY9L6hgMYdyQRNhy8G1MSFA0NtB7f5yP01PnXt9zfe891/TzfEhfne95fz/f73l/v/Z53XO/53vOTVUhSerHz6x0A5Kk8TL4JakzBr8kdcbgl6TOGPyS1JlzVrqB07noootq48aNK92GJL2hPPHEE39RVRNzLT+rg3/jxo1MTU2tdBuS9IaS5LunW+6pHknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6sxZ/cndxdp4639f6RZW1Hc+8U8Wtb7Hz+O3GB6/xVns8TsdX/FLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6sy8wZ/k/CSPJflGksNJPtrqn07y7SQH27S51ZPkziTTSQ4luXxoWzuTPNemncu2V5KkOY3yXT2vAu+uqleSrAa+luRLbdm/qKrPnzL+WmBTm64A7gKuSHIhcBswCRTwRJJ9VfXSUuyIJGk0877ir4FX2t3VbarTrLIDuKet9whwQZK1wDXAgao60cL+ALBtce1LkhZqpHP8SVYlOQgcZxDej7ZFt7fTOXckOa/V1gEvDK1+pNXmqp/6WLuSTCWZmpmZWdjeSJLmNVLwV9XrVbUZWA9sSfIO4CPA24B/AFwI/MulaKiqdlfVZFVNTkxMLMUmJUlDFnRVT1X9AHgY2FZVx9rpnFeBPwG2tGFHgQ1Dq61vtbnqkqQxGuWqnokkF7T5NwHvAb7ZztuTJMB1wFNtlX3Aje3qnq3Ay1V1DHgQuDrJmiRrgKtbTZI0RqNc1bMW2JtkFYMfFPdV1QNJvpJkAghwEPhgG78f2A5MAz8GPgBQVSeSfBx4vI37WFWdWLI9kSSNZN7gr6pDwGWz1N89x/gCbp5j2R5gzwJ7lCQtIT+5K0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHVm3uBPcn6Sx5J8I8nhJB9t9UuSPJpkOsnnkpzb6ue1+9Nt+cahbX2k1Z9Ncs2y7ZUkaU6jvOJ/FXh3Vb0T2AxsS7IV+H3gjqr6O8BLwE1t/E3AS61+RxtHkkuB64G3A9uAP0yyagn3RZI0gnmDvwZeaXdXt6mAdwOfb/W9wHVtfke7T1t+VZK0+r1V9WpVfRuYBrYsxU5IkkY30jn+JKuSHASOAweAbwE/qKrX2pAjwLo2vw54AaAtfxn4ueH6LOsMP9auJFNJpmZmZha8Q5Kk0xsp+Kvq9araDKxn8Cr9bcvVUFXtrqrJqpqcmJhYroeRpG4t6KqeqvoB8DDwS8AFSc5pi9YDR9v8UWADQFv+s8D3h+uzrCNJGpNRruqZSHJBm38T8B7gGQY/AN7bhu0E7m/z+9p92vKvVFW1+vXtqp9LgE3AY0u0H5KkEZ0z/xDWAnvbFTg/A9xXVQ8keRq4N8m/Bv4cuLuNvxv4z0mmgRMMruShqg4nuQ94GngNuLmqXl/a3ZEkzWfe4K+qQ8Bls9SfZ5arcqrq/wD/dI5t3Q7cvvA2JUlLxU/uSlJnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqzCh/bH1DkoeTPJ3kcJIPtfrvJTma5GCbtg+t85Ek00meTXLNUH1bq00nuXV5dkmSdDqj/LH114DfrqqvJ3kL8ESSA23ZHVX174YHJ7mUwR9Yfzvwt4EvJ/m7bfGngPcAR4DHk+yrqqeXYkckSaMZ5Y+tHwOOtfkfJXkGWHeaVXYA91bVq8C3k0zzl3+Ufbr9kXaS3NvGGvySNEYLOsefZCNwGfBoK92S5FCSPUnWtNo64IWh1Y602lz1Ux9jV5KpJFMzMzMLaU+SNIKRgz/Jm4EvAB+uqh8CdwFvBTYz+I3gD5aioaraXVWTVTU5MTGxFJuUJA0Z5Rw/SVYzCP3PVNUXAarqxaHlfwQ80O4eBTYMrb6+1ThNXZI0JqNc1RPgbuCZqvrkUH3t0LBfA55q8/uA65Ocl+QSYBPwGPA4sCnJJUnOZfAG8L6l2Q1J0qhGecX/LuD9wJNJDrba7wA3JNkMFPAd4LcAqupwkvsYvGn7GnBzVb0OkOQW4EFgFbCnqg4v2Z5IkkYyylU9XwMyy6L9p1nnduD2Wer7T7eeJGn5+cldSeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTPzBn+SDUkeTvJ0ksNJPtTqFyY5kOS5drum1ZPkziTTSQ4luXxoWzvb+OeS7Fy+3ZIkzWWUV/yvAb9dVZcCW4Gbk1wK3Ao8VFWbgIfafYBrgU1t2gXcBYMfFMBtwBXAFuC2kz8sJEnjM2/wV9Wxqvp6m/8R8AywDtgB7G3D9gLXtfkdwD018AhwQZK1wDXAgao6UVUvAQeAbUu5M5Kk+S3oHH+SjcBlwKPAxVV1rC36HnBxm18HvDC02pFWm6t+6mPsSjKVZGpmZmYh7UmSRjBy8Cd5M/AF4MNV9cPhZVVVQC1FQ1W1u6omq2pyYmJiKTYpSRoyUvAnWc0g9D9TVV9s5RfbKRza7fFWPwpsGFp9favNVZckjdEoV/UEuBt4pqo+ObRoH3DyypydwP1D9Rvb1T1bgZfbKaEHgauTrGlv6l7dapKkMTpnhDHvAt4PPJnkYKv9DvAJ4L4kNwHfBd7Xlu0HtgPTwI+BDwBU1YkkHwceb+M+VlUnlmInJEmjmzf4q+prQOZYfNUs4wu4eY5t7QH2LKRBSdLS8pO7ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6M8ofW9+T5HiSp4Zqv5fkaJKDbdo+tOwjSaaTPJvkmqH6tlabTnLr0u+KJGkUo7zi/zSwbZb6HVW1uU37AZJcClwPvL2t84dJViVZBXwKuBa4FLihjZUkjdkof2z9q0k2jri9HcC9VfUq8O0k08CWtmy6qp4HSHJvG/v0wluWJC3GYs7x35LkUDsVtKbV1gEvDI050mpz1X9Kkl1JppJMzczMLKI9SdJszjT47wLeCmwGjgF/sFQNVdXuqpqsqsmJiYml2qwkqZn3VM9squrFk/NJ/gh4oN09CmwYGrq+1ThNXZI0Rmf0ij/J2qG7vwacvOJnH3B9kvOSXAJsAh4DHgc2JbkkybkM3gDed+ZtS5LO1Lyv+JN8FrgSuCjJEeA24Mokm4ECvgP8FkBVHU5yH4M3bV8Dbq6q19t2bgEeBFYBe6rq8FLvjCRpfqNc1XPDLOW7TzP+duD2Wer7gf0L6k6StOT85K4kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUmXmDP8meJMeTPDVUuzDJgSTPtds1rZ4kdyaZTnIoyeVD6+xs459LsnN5dkeSNJ9RXvF/Gth2Su1W4KGq2gQ81O4DXAtsatMu4C4Y/KAAbgOuALYAt538YSFJGq95g7+qvgqcOKW8A9jb5vcC1w3V76mBR4ALkqwFrgEOVNWJqnoJOMBP/zCRJI3BmZ7jv7iqjrX57wEXt/l1wAtD44602lz1n5JkV5KpJFMzMzNn2J4kaS6LfnO3qgqoJejl5PZ2V9VkVU1OTEws1WYlSc2ZBv+L7RQO7fZ4qx8FNgyNW99qc9UlSWN2psG/Dzh5Zc5O4P6h+o3t6p6twMvtlNCDwNVJ1rQ3da9uNUnSmJ0z34AknwWuBC5KcoTB1TmfAO5LchPwXeB9bfh+YDswDfwY+ABAVZ1I8nHg8TbuY1V16hvGkqQxmDf4q+qGORZdNcvYAm6eYzt7gD0L6k6StOT85K4kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4sKviTfCfJk0kOJplqtQuTHEjyXLtd0+pJcmeS6SSHkly+FDsgSVqYpXjF/4+qanNVTbb7twIPVdUm4KF2H+BaYFObdgF3LcFjS5IWaDlO9ewA9rb5vcB1Q/V7auAR4IIka5fh8SVJp7HY4C/gfyZ5IsmuVru4qo61+e8BF7f5dcALQ+seabW/IsmuJFNJpmZmZhbZniTpVOcscv1fqaqjSf4mcCDJN4cXVlUlqYVssKp2A7sBJicnF7SuJGl+i3rFX1VH2+1x4E+BLcCLJ0/htNvjbfhRYMPQ6utbTZI0Rmcc/En+RpK3nJwHrgaeAvYBO9uwncD9bX4fcGO7umcr8PLQKSFJ0pgs5lTPxcCfJjm5nf9SVf8jyePAfUluAr4LvK+N3w9sB6aBHwMfWMRjS5LO0BkHf1U9D7xzlvr3gatmqRdw85k+niRpafjJXUnqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzYw/+JNuSPJtkOsmt4358SerdWIM/ySrgU8C1wKXADUkuHWcPktS7cb/i3wJMV9XzVfV/gXuBHWPuQZK6lqoa34Ml7wW2VdVvtvvvB66oqluGxuwCdrW7fw949jSbvAj4i2VqdynY3+LY3+LY3+K8kfv7+aqamGvFc5annzNXVbuB3aOMTTJVVZPL3NIZs7/Fsb/Fsb/F+evc37hP9RwFNgzdX99qkqQxGXfwPw5sSnJJknOB64F9Y+5Bkro21lM9VfVakluAB4FVwJ6qOryITY50SmgF2d/i2N/i2N/i/LXtb6xv7kqSVp6f3JWkzhj8ktSZN1TwJ7kwyYEkz7XbNXOMez3JwTYt65vH830FRZLzknyuLX80ycbl7OcM+vuNJDNDx+s3x9zfniTHkzw1x/IkubP1fyjJ5WdZf1cmeXno+P3umPvbkOThJE8nOZzkQ7OMWbFjOGJ/K3YMk5yf5LEk32j9fXSWMSv2HB6xv4U/h6vqDTMB/xa4tc3fCvz+HONeGVM/q4BvAb8AnAt8A7j0lDH/HPhPbf564HNjPF6j9PcbwH9cwX/TfwhcDjw1x/LtwJeAAFuBR8+y/q4EHljB47cWuLzNvwX437P8G6/YMRyxvxU7hu2YvLnNrwYeBbaeMmYln8Oj9Lfg5/Ab6hU/g6932Nvm9wLXrVwrwGhfQTHc8+eBq5LkLOpvRVXVV4ETpxmyA7inBh4BLkiydjzdjdTfiqqqY1X19Tb/I+AZYN0pw1bsGI7Y34ppx+SVdnd1m0694mXFnsMj9rdgb7Tgv7iqjrX57wEXzzHu/CRTSR5Jct0y9rMOeGHo/hF++j/1T8ZU1WvAy8DPLWNPsz52M1t/AL/eTgF8PsmGWZavpFH3YSX9UvtV/EtJ3r5STbRTEJcxeFU47Kw4hqfpD1bwGCZZleQgcBw4UFVzHr8VeA6P0h8s8Dl81gV/ki8neWqW6a+8Uq3B7zhz/eT7+Rp8lPmfAf8+yVuXu+83sP8GbKyqXwQO8JevbDSarzP4//ZO4D8Af7YSTSR5M/AF4MNV9cOV6OF05ulvRY9hVb1eVZsZfJPAliTvGOfjz2eE/hb8HD7rgr+q/nFVvWOW6X7gxZO/orbb43Ns42i7fR74XwxeZSyHUb6C4idjkpwD/Czw/WXq51Tz9ldV36+qV9vdPwb+/ph6G9VZ/TUfVfXDk7+KV9V+YHWSi8bZQ5LVDEL1M1X1xVmGrOgxnK+/s+EYtsf+AfAwsO2URSv5HP6Jufo7k+fwWRf889gH7GzzO4H7Tx2QZE2S89r8RcC7gKeXqZ9RvoJiuOf3Al9pv62Mw7z9nXKu91cZnIM9m+wDbmxXpmwFXh463bfikvytk+d7k2xh8JwaWyi0x74beKaqPjnHsBU7hqP0t5LHMMlEkgva/JuA9wDfPGXYij2HR+nvjJ7D43p3eikmBufVHgKeA74MXNjqk8Aft/lfBp5kcAXLk8BNy9zTdgZXKnwL+Fet9jHgV9v8+cB/BaaBx4BfGPMxm6+/fwMcbsfrYeBtY+7vs8Ax4P8xOPd8E/BB4INteRj88Z5vtX/PybOsv1uGjt8jwC+Pub9fYXDK8xBwsE3bz5ZjOGJ/K3YMgV8E/rz19xTwu61+VjyHR+xvwc9hv7JBkjrzRjvVI0laJINfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdeb/A0p4Do199AnHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_oh_ovs, labels_oh_ovs = oversample_smote(data_oh, labels_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the models with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=2, n=3765 (25.000%)\n",
      "Class=1, n=3765 (25.000%)\n",
      "Class=3, n=3765 (25.000%)\n",
      "Class=0, n=3765 (25.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ovs, labels_ovs = oversample_smote(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_data(data_ovs, lables_ovs, one_hot=False):\n",
    "    dimensions_labels = len(np.unique(labels_ovs))\n",
    "    labels_encoded = tf.one_hot(indices=labels_ovs, depth=dimensions_labels)\n",
    "    labels_encoded = np.asarray(labels_encoded)\n",
    "\n",
    "    indices = np.arange(data_ovs.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    data_ovs = data_ovs[indices]\n",
    "    labels_encoded = labels_encoded[indices]\n",
    "\n",
    "    training_samples = int(0.8 * len(data_ovs))\n",
    "\n",
    "    x_train = data_ovs[:training_samples]\n",
    "    y_train = labels_encoded[:training_samples]\n",
    "\n",
    "    x_val = data_ovs[training_samples:]\n",
    "    y_val = labels_encoded[training_samples:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_oh, y_train_oh, x_val_oh, y_val_oh = train_val_data(\n",
    "    data_oh_ovs, labels_oh_ovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = train_val_data(data_ovs, labels_ovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(model, hidden_units, embedding_size=None, conv_window=None):\n",
    "    # baseline model\n",
    "    if model == PARAMS['models'][0]:\n",
    "        model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "    # fully connected bag-of-words\n",
    "    elif model == PARAMS['models'][1]:\n",
    "        model.add(layers.Dense(hidden_units, activation='relu',\n",
    "                               input_shape=(max_words, )))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "    # fully connected & \"homegrown\" embeddings layer\n",
    "    elif model == PARAMS['models'][1]:\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_size, input_length=max_len))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(hidden_units, activation='relu',\n",
    "                               input_shape=(max_words, )))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "    # fully connected & a pre-trained embeddings layer\n",
    "    elif model == PARAMS['models'][2]:\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_dim, input_length=max_len))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(hidden_units, activation='relu',\n",
    "                               input_shape=(max_words, )))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "        model.layers[0].set_weights([embedding_matrix])  # !!!! important !!!!\n",
    "        model.layers[0].trainable = False\n",
    "\n",
    "    # lstm with \"homegrowm\" embeddings layer\n",
    "    elif model == PARAMS['models'][3]:\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_dim, input_length=max_len))\n",
    "        model.add(layers.LSTM(hidden_units))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "    # lstm with pre-trained embeddings layer\n",
    "    elif model == PARAMS['models'][4]:\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_dim, input_length=max_len))\n",
    "        model.add(layers.LSTM(hidden_units))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(hidden_units, activation='relu'))\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "        model_lstm.layers[0].set_weights([embedding_matrix])  # !!!! important !!!!\n",
    "        model_lstm.layers[0].trainable = False\n",
    "\n",
    "    # conv1D with \"homegrown\" embeddings layer\n",
    "    elif model == PARAMS['models'][5]:\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_size, input_length=max_len))\n",
    "\n",
    "        model.add(layers.Conv1D(\n",
    "            hidden_units,  # features to be extracted\n",
    "            conv_window,  # convolutional window size\n",
    "            activation='relu',\n",
    "        ))\n",
    "        model.add(layers.Conv1D(hidden_units, conv_window, activation='relu'))\n",
    "        model.add(layers.GlobalMaxPooling1D())\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "    # conv1D with pre-trained embeddings layer\n",
    "    elif model == PARAMS['models'][6]:\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Embedding(max_words+1,\n",
    "                                   embedding_dim, input_length=max_len))\n",
    "\n",
    "        model.add(layers.Conv1D(hidden_units, conv_window, activation='relu',))\n",
    "        model.add(layers.Conv1D(hidden_units, conv_window, activation='relu'))\n",
    "        model.add(layers.GlobalMaxPooling1D())\n",
    "        model.add(layers.Dense(dimensions_labels, activation='softmax'))\n",
    "\n",
    "        model.layers[0].set_weights([embedding_matrix])  # !!!! important !!!!\n",
    "        model.layers[0].trainable = False\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-sent",
   "language": "python",
   "name": "nlp-sent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
