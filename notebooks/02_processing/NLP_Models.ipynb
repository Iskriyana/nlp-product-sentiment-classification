{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "\n",
    "# This tokenizer is nice, but could cause problems.\n",
    "try:\n",
    "    from nltk.tokenize.moses import MosesDetokenizer\n",
    "    detokenizer = MosesDetokenizer()\n",
    "    use_moses_detokenizer = True\n",
    "except:\n",
    "    use_moses_detokenizer = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "home = os.getenv(\"HOME\")\n",
    "nlp_repo = os.path.join(home, 'git/nlp-product-sentiment-classification')\n",
    "\n",
    "# Data\n",
    "train_csv_path = os.path.join(nlp_repo, 'data/03_processed/Train.csv')\n",
    "train_descr = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Encoded Tokens\n",
    "preprocessed_corpus_path = os.path.join(\n",
    "    nlp_repo, 'data/03_processed/product_descr_preprocessed.p')\n",
    "\n",
    "# Training parameters\n",
    "train_anyway = False\n",
    "model_path = \"product_descr.h5\"\n",
    "#dataset_size = 5000\n",
    "sequence_length = 30\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "hidden_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning the Encoded Sequences into a Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vocabulary = pd.read_pickle(preprocessed_corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "* TF dataset: https://stackoverflow.com/questions/58362316/how-do-i-go-from-pandas-dataframe-to-tensorflow-batchdataset-for-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    indices, padding='post', value=len(vocabulary))\n",
    "train_labels = train_descr['Sentiment'].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 154 3719  294 ... 7119 7119 7119]\n",
      " [   4    1   24 ... 7119 7119 7119]\n",
      " [ 451    6   22 ... 7119 7119 7119]\n",
      " ...\n",
      " [   4    1    4 ... 7119 7119 7119]\n",
      " [ 204  256   16 ... 7119 7119 7119]\n",
      " [   5   13 7118 ... 7119 7119 7119]]\n",
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_seqs)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_seqs, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check, if transformation went ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descr, test_label = list(train_ds.take(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 154, 3719,  294,  450,   17,   11,   18,    1,    2,    0, 7119,\n",
       "       7119, 7119, 7119, 7119, 7119, 7119, 7119, 7119, 7119, 7119, 7119,\n",
       "       7119, 7119, 7119], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_descr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: import from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_indices(indices, vocabulary):\n",
    "    \"\"\" Decodes a sequence of indices and returns a string. \"\"\"\n",
    "    # adding an extra item for padding in order to keep the decoding correct after padding\n",
    "    # if we use the default value 0 for padding, it would be translated to one of our tokens\n",
    "    vocabulary.append('padding')\n",
    "    decoded_tokens = [vocabulary[index] for index in indices]\n",
    "    if use_moses_detokenizer == True:\n",
    "        return detokenizer.detokenize(decoded_tokens, return_str=True)\n",
    "    else:\n",
    "        return \" \".join(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web designeruas guide ios android app today mention link sxsw padding padding padding padding padding padding padding padding padding padding padding padding padding padding padding'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_test_descr = decode_indices(test_descr, vocabulary)\n",
    "decoded_test_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-sent",
   "language": "python",
   "name": "nlp-sent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
